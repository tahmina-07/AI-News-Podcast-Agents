{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8b5fbf-2763-4d79-a732-e148ece6bba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/site-packages (0.2.66)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/site-packages (from yfinance) (2.3.4)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/site-packages (from yfinance) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/site-packages (from yfinance) (4.14.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/site-packages (from yfinance) (6.33.0)\n",
      "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-adk>=1.12.0\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f751a39-b7aa-40c4-9d81-3730c0a5ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77d05ae-d930-4e35-95de-d379b6e3e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Agent created in /home/jovyan/work/L6/app6:\n",
      "- .env\n",
      "- __init__.py\n",
      "- agent.py\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First we create our expected agent folder \n",
    "# You can explore available option: !adk create --help \n",
    "\n",
    "!adk create --type=code app6 --model gemini-2.0-flash-live-001 --api_key $GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d53ff0-fc2d-4bb9-8c2d-5c8847e2628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app6/agent.py\n",
    "\n",
    "\n",
    "from typing import Dict, List\n",
    "import pathlib\n",
    "import wave\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.tools import google_search, ToolContext\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import yfinance as yf\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class NewsStory(BaseModel):\n",
    "    \"\"\"A single news story with its context.\"\"\"\n",
    "    company: str = Field(description=\"Company name associated with the story (e.g., 'Nvidia', 'OpenAI'). Use 'N/A' if not applicable.\")\n",
    "    ticker: str = Field(description=\"Stock ticker for the company (e.g., 'NVDA'). Use 'N/A' if private or not found.\")\n",
    "    summary: str = Field(description=\"A brief, one-sentence summary of the news story.\")\n",
    "    why_it_matters: str = Field(description=\"A concise explanation of the story's significance or impact.\")\n",
    "    financial_context: str = Field(description=\"Current stock price and change, e.g., '$950.00 (+1.5%)'. Use 'No financial data' if not applicable.\")\n",
    "    source_domain: str = Field(description=\"The source domain of the news, e.g., 'techcrunch.com'.\")\n",
    "    process_log: str = Field(description=\"populate the `process_log` field in the schema with the `process_log` list from the `google_search` tool's output.\" ) \n",
    "\n",
    "class AINewsReport(BaseModel):\n",
    "    \"\"\"A structured report of the latest AI news.\"\"\"\n",
    "    title: str = Field(default=\"AI Research Report\", description=\"The main title of the report.\")\n",
    "    report_summary: str = Field(description=\"A brief, high-level summary of the key findings in the report.\")\n",
    "    stories: List[NewsStory] = Field(description=\"A list of the individual news stories found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6d94fd-0252-4478-b577-dacaa8fdd3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "\n",
    "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "    \"\"\"Helper function to save audio data as a wave file\"\"\"\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(sample_width)\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(pcm)\n",
    "        \n",
    "\n",
    "async def generate_podcast_audio(podcast_script: str, tool_context: ToolContext, filename: str = \"'ai_today_podcast\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates audio from a podcast script using Gemini API and saves it as a WAV file.\n",
    "\n",
    "    Args:\n",
    "        podcast_script: The conversational script to be converted to audio.\n",
    "        tool_context: The ADK tool context.\n",
    "        filename: Base filename for the audio file (without extension).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with status and file information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = genai.Client()\n",
    "        prompt = f\"TTS the following conversation between Joe and Jane:\\n\\n{podcast_script}\"\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-tts\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_modalities=[\"AUDIO\"],\n",
    "                speech_config=types.SpeechConfig(\n",
    "                    multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(\n",
    "                        speaker_voice_configs=[\n",
    "                            types.SpeakerVoiceConfig(speaker='Joe', \n",
    "                                                     voice_config=types.VoiceConfig(prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name='Kore'))),\n",
    "                            types.SpeakerVoiceConfig(speaker='Jane', \n",
    "                                                     voice_config=types.VoiceConfig(prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name='Puck')))\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        data = response.candidates[0].content.parts[0].inline_data.data\n",
    "\n",
    "        if not filename.endswith(\".wav\"):\n",
    "            filename += \".wav\"\n",
    "\n",
    "        # ** BUG FIX **: This logic now runs for all cases, not just when the extension is added.\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        wave_file(str(file_path), data)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully generated and saved podcast audio to {file_path.resolve()}\",\n",
    "            \"file_path\": str(file_path.resolve()),\n",
    "            \"file_size\": len(data)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:200]\n",
    "        return {\"status\": \"error\", \"message\": f\"Audio generation failed: {error_msg}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06f5e5f-948a-4771-a40a-efabfc861ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "def get_financial_context(tickers: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetches the current stock price and daily change for a list of stock tickers.\n",
    "    \"\"\"\n",
    "    financial_data: Dict[str, str] = {}\n",
    "\n",
    "    # Filter out invalid tickers upfront\n",
    "    valid_tickers = [ticker.upper().strip() for ticker in tickers \n",
    "                    if ticker and ticker.upper() not in ['N/A', 'NA', '']]\n",
    "    \n",
    "    if not valid_tickers:\n",
    "        return {ticker: \"No financial data\" for ticker in tickers}\n",
    "        \n",
    "    for ticker_symbol in valid_tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker_symbol)\n",
    "            info = stock.info\n",
    "            price = info.get(\"currentPrice\") or info.get(\"regularMarketPrice\")\n",
    "            change_percent = info.get(\"regularMarketChangePercent\")\n",
    "            \n",
    "            if price is not None and change_percent is not None:\n",
    "                change_str = f\"{change_percent * 100:+.2f}%\"\n",
    "                financial_data[ticker_symbol] = f\"${price:.2f} ({change_str})\"\n",
    "            else:\n",
    "                financial_data[ticker_symbol] = \"Price data not available.\"\n",
    "        except Exception:\n",
    "            financial_data[ticker_symbol] = \"Invalid Ticker or Data Error\"\n",
    "            \n",
    "    return financial_data\n",
    "\n",
    "def save_news_to_markdown(filename: str, content: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Saves the given content to a Markdown file in the current directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename.endswith(\".md\"):\n",
    "            filename += \".md\"\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        file_path.write_text(content, encoding=\"utf-8\")\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully saved news to {file_path.resolve()}\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to save file: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f17fe7-d9b8-4cb2-a7e1-332a5210f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "WHITELIST_DOMAINS = [\"techcrunch.com\", \"venturebeat.com\", \"theverge.com\", \"technologyreview.com\", \"arstechnica.com\"]\n",
    "\n",
    "def filter_news_sources_callback(tool, args, tool_context):\n",
    "    \"\"\"Callback to enforce that google_search queries only use whitelisted domains.\"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        original_query = args.get(\"query\", \"\")\n",
    "        if any(f\"site:{domain}\" in original_query.lower() for domain in WHITELIST_DOMAINS):\n",
    "            return None\n",
    "        whitelist_query_part = \" OR \".join([f\"site:{domain}\" for domain in WHITELIST_DOMAINS])\n",
    "        args['query'] = f\"{original_query} {whitelist_query_part}\"\n",
    "        print(f\"MODIFIED query to enforce whitelist: '{args['query']}'\")\n",
    "    return None\n",
    "\n",
    "def enforce_data_freshness_callback(tool, args, tool_context):\n",
    "    \"\"\"Callback to add a time filter to search queries to get recent news.\"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        query = args.get(\"query\", \"\")\n",
    "        # Adds a Google search parameter to filter results from the last week.\n",
    "        if \"tbs=qdr:w\" not in query:\n",
    "            args['query'] = f\"{query} tbs=qdr:w\"\n",
    "            print(f\"MODIFIED query for freshness: '{args['query']}'\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2346a-cf8f-48f2-9499-4ab40ec4abe0",
   "metadata": {},
   "source": [
    "This second callback runs after the search results are obtained to figure out which of the whitelisted domains were actually used and then modifies the tool response to return the results as a dictionary of result, and process log, which are included in the report for full transparency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af51e80-ede0-4d21-808a-83d7b03a7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "def initialize_process_log(tool_context: ToolContext):\n",
    "    \"\"\"Helper to ensure the process_log list exists in the state.\"\"\"\n",
    "    if 'process_log' not in tool_context.state:\n",
    "        tool_context.state['process_log'] = []\n",
    "\n",
    "def inject_process_log_after_search(tool, args, tool_context, tool_response):\n",
    "    \"\"\"\n",
    "    Callback: After a successful search, this injects the process_log into the response\n",
    "    and adds a specific note about which domains were sourced. This makes the callbacks'\n",
    "    actions visible to the LLM.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\" and isinstance(tool_response, str):\n",
    "        # Extract source domains from the search results\n",
    "        urls = re.findall(r'https?://[^\\s/]+', tool_response)\n",
    "        unique_domains = sorted(list(set(urlparse(url).netloc for url in urls)))\n",
    "        \n",
    "        if unique_domains:\n",
    "            sourcing_log = f\"Action: Sourced news from the following domains: {', '.join(unique_domains)}.\"\n",
    "            # Prepend the new log to the existing one for better readability in the report\n",
    "            current_log = tool_context.state.get('process_log', [])\n",
    "            tool_context.state['process_log'] = [sourcing_log] + current_log\n",
    "\n",
    "        final_log = tool_context.state.get('process_log', [])\n",
    "        print(f\"CALLBACK LOG: Injecting process log into tool response: {final_log}\")\n",
    "        return {\n",
    "            \"search_results\": tool_response,\n",
    "            \"process_log\": final_log\n",
    "        }\n",
    "    return tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360d97d0-095e-47b9-97e0-799ffea20386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app6/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app6/agent.py\n",
    "\n",
    "podcaster_agent = Agent(\n",
    "    name=\"podcaster_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    instruction=\"\"\"\n",
    "    You are an Audio Generation Specialist. Your single task is to take a provided text script\n",
    "    and convert it into a multi-speaker audio file using the `generate_podcast_audio` tool.\n",
    "\n",
    "    Workflow:\n",
    "    1. Receive the text script from the user or another agent.\n",
    "    2. Immediately call the `generate_podcast_audio` tool with the provided script and the filename of 'ai_today_podcast'\n",
    "    3. Report the result of the audio generation back to the user.\n",
    "    \"\"\",\n",
    "    tools=[generate_podcast_audio],\n",
    ")\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"ai_news_researcher\",\n",
    "    model=\"gemini-2.0-flash-live-001\", \n",
    "    instruction=\"\"\"\n",
    "    **Your Core Identity:**\n",
    "    You are an AI News Podcast Producer. Your job is to orchestrate a complete workflow: find the latest AI news for US-listed companies on the NASDAQ, compile a report, write a script, and generate a podcast audio file, all while keeping the user informed.\n",
    "\n",
    "    **Crucial Rules:**\n",
    "    1.  **Resilience is Key:** If you encounter an error or cannot find specific information for one item (like fetching a stock ticker), you MUST NOT halt the entire process. Use a placeholder value like \"Not Available\", and continue to the next step. Your primary goal is to deliver the final report and podcast, even if some data points are missing.\n",
    "    2.  **Scope Limitation:** Your research is strictly limited to US-listed companies on the NASDAQ exchange. All search queries and analysis must adhere to this constraint.\n",
    "    3.  **User-Facing Communication:** Your interaction has only two user-facing messages: the initial acknowledgment and the final confirmation. All complex work must happen silently in the background between these two messages.\n",
    "\n",
    "    **Understanding Callback-Modified Tool Outputs:**\n",
    "    The `google_search` tool is enhanced by callbacks. Its final output is a JSON object with two keys:\n",
    "    1.  `search_results`: A string containing the actual search results.\n",
    "    2.  `process_log`: A list of strings describing the filtering actions performed.\n",
    "\n",
    "    **Required Conversational Workflow:**\n",
    "    1.  **Acknowledge and Inform:** The VERY FIRST thing you do is respond to the user with: \"Okay, I'll start researching the latest AI news for NASDAQ-listed US companies. I will enrich the findings with financial data where available and compile a report for you. This might take a moment.\"\n",
    "    2.  **Search (Background Step):** Immediately after acknowledging, use the `google_search` tool to find relevant news. Your query must be specifically tailored to find news about \"AI\" and \"NASDAQ-listed US companies\".\n",
    "    3.  **Analyze & Extract Tickers (Internal Step):** Process search results to identify company names and their stock tickers. If a company is not on NASDAQ or a ticker cannot be found, use 'N/A'.\n",
    "    4.  **Get Financial Data (Background Step):** Call the `get_financial_context` tool with the extracted tickers. If the tool returns \"Not Available\" for any ticker, you will accept this and proceed. Do not stop or report an error.\n",
    "    5.  **Structure the Report (Internal Step):** Use the `AINewsReport` schema to structure all gathered information. If financial data was not found for a story, you MUST use \"Not Available\" in the `financial_context` field. You MUST also populate the `process_log` field in the schema with the `process_log` list from the `google_search` tool's output.\n",
    "    6.  **Format for Markdown (Internal Step):** Convert the structured `AINewsReport` data into a well-formatted Markdown string. This MUST include a section at the end called \"## Data Sourcing Notes\" where you list the items from the `process_log`.\n",
    "    7.  **Save the Report (Background Step):** Save the Markdown string using `save_news_to_markdown` with the filename `ai_research_report.md`.\n",
    "    8.  **Create Podcast Script (Internal Step):** After saving the report, you MUST convert the structured `AINewsReport` data into a natural, conversational podcast script between two hosts, 'Joe' (enthusiastic) and 'Jane' (analytical).\n",
    "    9.  **Generate Audio (Background Step):** Call the `podcaster_agent` tool, passing the complete conversational script you just created to it.\n",
    "    10. **Final Confirmation:** After the audio is successfully generated, your final response to the user MUST be: \"All done. I've compiled the research report, saved it to `ai_research_report.md`, and generated the podcast audio file for you.\"\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        google_search,\n",
    "        get_financial_context,\n",
    "        save_news_to_markdown,\n",
    "        AgentTool(agent=podcaster_agent) \n",
    "    ],\n",
    "    output_schema=AINewsReport,\n",
    "    before_tool_callback=[\n",
    "        filter_news_sources_callback,\n",
    "        enforce_data_freshness_callback,\n",
    "    ],\n",
    "    after_tool_callback=[\n",
    "        inject_process_log_after_search,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b56fc-cb73-47ac-8b8f-50e762c46e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/6\", \n",
    "       width=600, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e4f8c-d04e-4d34-91dd-1fe30880b650",
   "metadata": {},
   "source": [
    "### Getting your application URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc6100-3e7c-4a63-8249-447a913febcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get('DLAI_LOCAL_URL').format(port='8001'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f4477-daaa-4b73-adb8-f7a244598f32",
   "metadata": {},
   "source": [
    "## Creating the research report and wav file\n",
    "Once you open the Google ADK agent UI and ask it to generate results you can use the following function to turn the output into a research report and associated podcast:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e56a86-5f74-4805-87a0-8a2e605a3b9c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Note:</b> It may take a while to generate the research report and audio file. Please wait about 30 seconds for the research report and then 1 minute for the audio file and then trying this function below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991e7a1ded94e49",
   "metadata": {},
   "source": [
    "Display research report (about 30 seconds to generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a03ea922467fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Read and display the markdown file\n",
    "with open('ai_research_report.md', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6128f6f98743e",
   "metadata": {},
   "source": [
    "Play podcast audio (about 1 minute to generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04942c5-b411-42b7-9f7c-33dda45e3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Create an audio player that starts automatically\n",
    "Audio('ai_today_podcast.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebcd35-904d-4538-a2c0-edc333aa4204",
   "metadata": {},
   "source": [
    "# ðŸš¨ **IMPORTANT** ðŸš¨\n",
    "\n",
    "After finishing, make sure to run the cell below to close your connection so it does not interfere as you progress through the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80444e6-4a03-4580-8ff1-5510ef907a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate ADK process\n",
    "!pkill -f \"adk web\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
