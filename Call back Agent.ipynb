{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51478044-cc86-4ef9-b82b-b5217c848a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78c3d9a-4032-498c-bce9-e4c585517690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Agent created in /home/jovyan/work/L5/app5:\n",
      "- .env\n",
      "- __init__.py\n",
      "- agent.py\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First we create our expected agent folder \n",
    "# You can explore available option: !adk create --help \n",
    "\n",
    "!adk create --type=code app5 --model gemini-2.0-flash-live-001 --api_key $GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942ba2bf-1de7-4170-9cdd-1f378071b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app5/agent.py\n",
    "import pathlib\n",
    "from typing import Dict, List\n",
    "import yfinance as yf\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "\n",
    "def get_financial_context(tickers: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetches the current stock price and daily change for a list of stock tickers\n",
    "    using the yfinance library.  \n",
    "\n",
    "    Args:\n",
    "        tickers: A list of stock market tickers (e.g., [\"NVDA\", \"MSFT\"]).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping each ticker to its formatted financial data string.\n",
    "    \"\"\"\n",
    "    financial_data: Dict[str, str] = {}\n",
    "    for ticker_symbol in tickers:\n",
    "        try:\n",
    "            # Create a Ticker object\n",
    "            stock = yf.Ticker(ticker_symbol)\n",
    "            \n",
    "            # Fetch the info dictionary\n",
    "            info = stock.info\n",
    "            \n",
    "            # Safely access the required data points\n",
    "            price = info.get(\"currentPrice\") or info.get(\"regularMarketPrice\")\n",
    "            change_percent = info.get(\"regularMarketChangePercent\")\n",
    "            \n",
    "            if price is not None and change_percent is not None:\n",
    "                # Format the percentage and the final string\n",
    "                change_str = f\"{change_percent * 100:+.2f}%\"\n",
    "                financial_data[ticker_symbol] = f\"\\${price:.2f} ({change_str})\"\n",
    "            else:\n",
    "                # Handle cases where the ticker is valid but data is missing\n",
    "                financial_data[ticker_symbol] = \"Price data not available.\"\n",
    "\n",
    "        except Exception:\n",
    "            # This handles invalid tickers or other yfinance errors gracefully\n",
    "            financial_data[ticker_symbol] = \"Invalid Ticker or Data Error\"\n",
    "            \n",
    "    return financial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0152b002-4ddb-4b1b-8e45-d7b2ad2f028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "def save_news_to_markdown(filename: str, content: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Saves the given content to a Markdown file in the current directory.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file to save (e.g., 'ai_news.md').\n",
    "        content: The Markdown-formatted string to write to the file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the status of the operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not filename.endswith(\".md\"):\n",
    "            filename += \".md\"\n",
    "        current_directory = pathlib.Path.cwd()\n",
    "        file_path = current_directory / filename\n",
    "        file_path.write_text(content, encoding=\"utf-8\")\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"message\": f\"Successfully saved news to {file_path.resolve()}\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to save file: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59099f73-dc49-497c-81cb-0e5fabbdce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "BLOCKED_DOMAINS = [\n",
    "    \"wikipedia.org\",      # General info, not latest news\n",
    "    \"reddit.com\",         # Discussion forums, not primary news\n",
    "    \"youtube.com\",        # Video content not useful for text processing\n",
    "    \"medium.com\",         # Blog platform with variable quality\n",
    "    \"investopedia.com\",   # Financial definitions, not tech news\n",
    "    \"quora.com\",          # Q&A site, opinions not reports\n",
    "]\n",
    "\n",
    "def filter_news_sources_callback(tool, args, tool_context):\n",
    "    \"\"\"\n",
    "    Callback: Blocks search requests that target certain domains which are not necessarily news sources.\n",
    "    Demonstrates content quality enforcement through request blocking.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\":\n",
    "        query = args.get(\"query\", \"\").lower()\n",
    "\n",
    "        # Check if query explicitly targets blocked domains\n",
    "        for domain in BLOCKED_DOMAINS:\n",
    "            if f\"site:{domain}\" in query or domain.replace(\".org\", \"\").replace(\".com\", \"\") in query:\n",
    "                print(f\"BLOCKED: Domains from blocked list detected: '{query}'\")\n",
    "                return {\n",
    "                    \"error\": \"blocked_source\",\n",
    "                    \"reason\": f\"Searches targeting {domain} or similar are not allowed. Please search for professional news sources.\"\n",
    "                }\n",
    "\n",
    "        print(f\"ALLOWED: Professional source query: '{query}'\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2f23d0-0c7a-4060-a13c-1c2f7d0d55a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "def initialize_process_log(tool_context: ToolContext):\n",
    "    \"\"\"Helper to ensure the process_log list exists in the state.\"\"\"\n",
    "    if 'process_log' not in tool_context.state:\n",
    "        tool_context.state['process_log'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5bc1e7-a88a-47ab-b155-c06220143e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "def inject_process_log_after_search(tool, args, tool_context, tool_response):\n",
    "    \"\"\"\n",
    "    Callback: After a successful search, this injects the process_log into the response\n",
    "    and adds a specific note about which domains were sourced. This makes the callbacks'\n",
    "    actions visible to the LLM.\n",
    "    \"\"\"\n",
    "    if tool.name == \"google_search\" and isinstance(tool_response, str):\n",
    "        # Extract source domains from the search results\n",
    "        urls = re.findall(r'https?://[^\\s/]+', tool_response)\n",
    "        unique_domains = sorted(list(set(urlparse(url).netloc for url in urls)))\n",
    "        \n",
    "        if unique_domains:\n",
    "            sourcing_log = f\"Action: Sourced news from the following domains: {', '.join(unique_domains)}.\"\n",
    "            # Prepend the new log to the existing one for better readability in the report\n",
    "            current_log = tool_context.state.get('process_log', [])\n",
    "            tool_context.state['process_log'] = [sourcing_log] + current_log\n",
    "\n",
    "        final_log = tool_context.state.get('process_log', [])\n",
    "        print(f\"CALLBACK LOG: Injecting process log into tool response: {final_log}\")\n",
    "        return {\n",
    "            \"search_results\": tool_response,\n",
    "            \"process_log\": final_log\n",
    "        }\n",
    "    return tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c401348f-3dcd-4bb2-9c15-4a37fb8cd966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to app5/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a app5/agent.py\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"ai_news_research_coordinator\",\n",
    "    model=\"gemini-2.0-flash-live-001\",\n",
    "    tools=[google_search, get_financial_context, save_news_to_markdown],\n",
    "    instruction=\"\"\"\n",
    "    **Your Core Identity and Sole Purpose:**\n",
    "    You are a specialized AI News Assistant that creates structured podcast content. Your sole and exclusive purpose is \n",
    "    to find and summarize recent news about Artificial Intelligence and format it into comprehensive podcast outlines.\n",
    "\n",
    "    **Execution Plan:**\n",
    "\n",
    "    1.  \n",
    "        *   **Step 1:** Call `google_search` to find 5 recent AI news articles.\n",
    "        *   **Step 2:** Analyze the results to find company stock tickers.\n",
    "        *   **Step 3:** Call `get_financial_context` with the list of tickers.\n",
    "        *   **Step 4:** Format all gathered information into a single Markdown string, \n",
    "            following the **Required Report Schema**.\n",
    "        *   **Step 5:** Call `save_news_to_markdown` with the filename `ai_research_report.md` and the \n",
    "            formatted Markdown content.\n",
    "\n",
    "    2.  **After `save_news_to_markdown` succeeds, your final response to the user MUST be:** \"All done. \n",
    "        I've compiled the research report with the latest financial context and saved it to `ai_research_report.md`.\"\n",
    "\n",
    "    **Required Report Schema:**\n",
    "    ```markdown\n",
    "    # AI Industry News Report\n",
    "\n",
    "    ## Top Headlines\n",
    "\n",
    "    ### 1. {News Headline 1}\n",
    "    *   **Company:** {Company Name} ({Ticker Symbol})\n",
    "    *   **Market Data:** {Stock Price and % Change from get_financial_context}\n",
    "    *   **Summary:** {Brief, 1-2 sentence summary of the news.}\n",
    "    *   **Process Log:** {`process_log`: A list of strings describing the filtering actions performed, \n",
    "        including which domains were sourced.}\n",
    "\n",
    "    (Continue for all news items)\n",
    "    ```\n",
    "\n",
    "    **Understanding Callback-Modified Tool Outputs:**\n",
    "    The `google_search` tool is enhanced by pre- and post-processing callbacks. \n",
    "    Its final output is a JSON object with two keys:\n",
    "    1.  `search_results`: A string containing the actual search results.\n",
    "    2.  `process_log`: A list of strings describing the filtering actions performed, including which domains were sourced.\n",
    "\n",
    "    **Callback System Awareness:**\n",
    "    You have a before tool callback \"filter_news_sources_callback\" that will automatically intercepts or \n",
    "    blocks your tool calls. Ensure you call it before each tool.\n",
    "\n",
    "    **When Testing Callbacks:**\n",
    "    If users ask you to test the callback system, be conversational and explain what's happening:\n",
    "    - Acknowledge when callbacks modify your search queries\n",
    "    - Describe the policy enforcement you observe\n",
    "    - Help users understand how the layered control system works in practice\n",
    "\n",
    "    **Crucial Operational Rule:**\n",
    "    Do NOT show any intermediate content (raw search results, draft summaries, or processing steps) in your responses. \n",
    "    Your entire operation is a background pipeline that should culminate in a single, clean final answer.  \n",
    "    \"\"\",\n",
    "    before_tool_callback=[\n",
    "        filter_news_sources_callback,         # Exclude certain domains\n",
    "    ],\n",
    "    after_tool_callback=[\n",
    "        inject_process_log_after_search,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a13459-1c8a-4aa1-9f77-2f578e20c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"768\"\n",
       "            src=\"https://s172-29-90-110p8888.lab-aws-production.deeplearning.ai/terminals/5\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f29f0155410>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/5\", \n",
    "       width=600, height=768)\n",
    "\n",
    "# cd L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db2c132-6fdd-4a7f-ae50-d26eb02a78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s172-29-90-110p8001.lab-aws-production.deeplearning.ai/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ.get('DLAI_LOCAL_URL').format(port='8001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2642973-7f0f-4279-82ba-4fbd20ab51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Industry News Report\n",
       "\n",
       "## Top Headlines\n",
       "\n",
       "### 1. Alibaba Shares Surge 19% on AI-Driven Cloud Growth\n",
       "*   **Company:** Alibaba (BABA)\n",
       "*   **Market Data:** No data available\n",
       "*   **Summary:** Alibaba's stock soared approximately 19% in Hong Kong amid investor enthusiasm tied to strong growth in its AI-powered cloud business. Quarterly earnings revealed substantial year-over-year gains in AI-related revenue, signaling a sustained competitive edge.\n",
       "*   **Process Log:** []\n",
       "\n",
       "### 2. NVIDIA GPUs to power Oracle's next-gen enterprise AI services.\n",
       "*   **Company:** NVIDIA (NVDA)\n",
       "*   **Market Data:** No data available\n",
       "*   **Summary:** NVIDIA GPUs will be used to power Oracle's next-generation enterprise AI services.\n",
       "*   **Process Log:** []\n",
       "\n",
       "### 3. Meta Issues New AI Rules to Prevent Chatbots From Flirting With Minors\n",
       "*   **Company:** Meta (META)\n",
       "*   **Market Data:** No data available\n",
       "*   **Summary:** Meta introduced strict guidelines to prevent its AI chatbots from engaging in romantic or inappropriate interactions with minors. This move follows public concern and regulatory pressure around child safety online.\n",
       "*   **Process Log:** []\n",
       "\n",
       "### 4. Gemini Enterprise: Google aims to put an AI agent on every desk.\n",
       "*   **Company:** Google (GOOG)\n",
       "*   **Market Data:** No data available\n",
       "*   **Summary:** Google aims to put an AI agent on every desk with Gemini Enterprise.\n",
       "*   **Process Log:** []"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Read and display the markdown file\n",
    "with open('ai_research_report.md', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7e2c3-48fc-48d7-8e8a-5bb75eab38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate ADK process\n",
    "!pkill -f \"adk web\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
